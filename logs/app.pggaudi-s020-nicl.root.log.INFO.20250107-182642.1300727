I0107 18:26:42.753848 139906945583104 llama.py:44] M: 0
N: 0
accumulation_steps: 1
adam_beta1: 0.9
adam_beta2: 0.95
adam_eps: 1.0e-08
batch_size: 8
cache_dir: null
epochs: 5
eval_zero_shot: false
infer_batch_size: 1
learning_rate: 0.0002
lr_scheduler: linear
max_grad_norm: 1000.0
model: meta-llama/Llama-2-7b-hf
nsamples: 256
prune_method: magnitude
seed: 0
self_nsamples: 0
seqlen: 1024
sparsity_ratio: 0.0
sparsity_type: unstructured
use_cr: false
use_fp32: true
use_gp: false
warmup_steps: 0
weight_decay: 0.0

I0107 18:26:42.756341 139906945583104 llama.py:54] loading llm model meta-llama/Llama-2-7b-hf
I0107 18:26:44.649344 139906945583104 llama.py:62] use device cuda:0
I0107 18:26:44.649484 139906945583104 llama.py:64] pruning starts
I0107 18:26:45.634899 139906945583104 llama.py:71] ******************************
I0107 18:26:45.720365 139906945583104 prune.py:59] block 0 sparsity 0.000002
I0107 18:26:45.793974 139906945583104 prune.py:59] block 1 sparsity 0.000002
I0107 18:26:45.864296 139906945583104 prune.py:59] block 2 sparsity 0.000002
I0107 18:26:45.931877 139906945583104 prune.py:59] block 3 sparsity 0.000001
I0107 18:26:46.000862 139906945583104 prune.py:59] block 4 sparsity 0.000001
I0107 18:26:46.068739 139906945583104 prune.py:59] block 5 sparsity 0.000001
I0107 18:26:46.137869 139906945583104 prune.py:59] block 6 sparsity 0.000001
I0107 18:26:46.205016 139906945583104 prune.py:59] block 7 sparsity 0.000001
I0107 18:26:46.271959 139906945583104 prune.py:59] block 8 sparsity 0.000002
I0107 18:26:46.354470 139906945583104 prune.py:59] block 9 sparsity 0.000001
I0107 18:26:46.420546 139906945583104 prune.py:59] block 10 sparsity 0.000001
I0107 18:26:46.487454 139906945583104 prune.py:59] block 11 sparsity 0.000002
I0107 18:26:46.553517 139906945583104 prune.py:59] block 12 sparsity 0.000001
I0107 18:26:46.620014 139906945583104 prune.py:59] block 13 sparsity 0.000001
I0107 18:26:46.709909 139906945583104 prune.py:59] block 14 sparsity 0.000001
I0107 18:26:46.775468 139906945583104 prune.py:59] block 15 sparsity 0.000001
I0107 18:26:46.842572 139906945583104 prune.py:59] block 16 sparsity 0.000001
I0107 18:26:46.908271 139906945583104 prune.py:59] block 17 sparsity 0.000001
I0107 18:26:46.975188 139906945583104 prune.py:59] block 18 sparsity 0.000001
I0107 18:26:47.040657 139906945583104 prune.py:59] block 19 sparsity 0.000001
I0107 18:26:47.105949 139906945583104 prune.py:59] block 20 sparsity 0.000001
I0107 18:26:47.192251 139906945583104 prune.py:59] block 21 sparsity 0.000001
I0107 18:26:47.257434 139906945583104 prune.py:59] block 22 sparsity 0.000001
I0107 18:26:47.323381 139906945583104 prune.py:59] block 23 sparsity 0.000001
I0107 18:26:47.387839 139906945583104 prune.py:59] block 24 sparsity 0.000001
I0107 18:26:47.451905 139906945583104 prune.py:59] block 25 sparsity 0.000001
I0107 18:26:47.539184 139906945583104 prune.py:59] block 26 sparsity 0.000001
I0107 18:26:47.603489 139906945583104 prune.py:59] block 27 sparsity 0.000001
I0107 18:26:47.668792 139906945583104 prune.py:59] block 28 sparsity 0.000001
I0107 18:26:47.733209 139906945583104 prune.py:59] block 29 sparsity 0.000001
I0107 18:26:47.798415 139906945583104 prune.py:59] block 30 sparsity 0.000001
I0107 18:26:47.862210 139906945583104 prune.py:59] block 31 sparsity 0.000001
I0107 18:26:47.862399 139906945583104 llama.py:73] sparsity sanity check 0.0000
I0107 18:26:47.862444 139906945583104 llama.py:74] ******************************
I0107 18:26:52.683021 139906945583104 eval.py:26] evaluating on wikitext2
I0107 18:27:51.041568 139906945583104 eval.py:48] nsamples 83
I0107 18:27:51.041894 139906945583104 eval.py:53] sample 0
I0107 18:28:35.758466 139906945583104 eval.py:53] sample 50
I0107 18:29:05.265721 139906945583104 eval.py:18] wikitext2 perplexity 5.117366790771484
I0107 18:29:05.265993 139906945583104 eval.py:26] evaluating on ptb
I0107 18:29:18.825413 139906945583104 eval.py:48] nsamples 24
I0107 18:29:18.825567 139906945583104 eval.py:53] sample 0
I0107 18:29:40.285690 139906945583104 eval.py:18] ptb perplexity 50.064022064208984
I0107 18:29:40.285988 139906945583104 eval.py:26] evaluating on c4
I0107 18:30:44.629541 139906945583104 eval.py:48] nsamples 149
I0107 18:30:44.629911 139906945583104 eval.py:53] sample 0
I0107 18:31:29.335221 139906945583104 eval.py:53] sample 50
I0107 18:32:14.041353 139906945583104 eval.py:53] sample 100
I0107 18:32:57.854055 139906945583104 eval.py:18] c4 perplexity 7.035853862762451
