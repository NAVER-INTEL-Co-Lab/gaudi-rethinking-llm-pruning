I0108 21:44:04.686417 140441555372032 opt.py:30] M: 0
N: 0
accumulation_steps: 1
adam_beta1: 0.9
adam_beta2: 0.95
adam_eps: 1.0e-08
batch_size: 8
cache_dir: llm_weights
epochs: 10
eval_zero_shot: false
infer_batch_size: 1
learning_rate: 0.0002
lr_scheduler: linear
max_grad_norm: 1000.0
model: facebook/opt-125m
nsamples: 256
prune_method: sparsegpt
seed: 0
self_nsamples: 0
seqlen: 1024
sparsity_ratio: 0.5
sparsity_type: unstructured
use_cr: false
use_fp32: true
use_gp: false
warmup_steps: 0
weight_decay: 0.0

I0108 21:44:04.688994 140441555372032 opt.py:40] loading llm model facebook/opt-125m
I0108 21:44:05.933716 140441555372032 opt.py:48] use device cuda:0
I0108 21:44:05.933871 140441555372032 opt.py:50] pruning starts
I0108 21:44:31.784213 140441555372032 prune.py:207] pruning layer 0
I0108 21:44:50.834491 140441555372032 finetune.py:129] weight params, number of params: 7087872, weight_decay: 0.0, lr: 0.0002
I0108 21:45:01.275590 140441555372032 finetune.py:123] [0.00011072680354118347, 0.00010029971599578857, 7.998943328857422e-05, 7.076561450958252e-05, 6.727874279022217e-05, 6.481260061264038e-05, 6.156414747238159e-05, 5.9664249420166016e-05, 5.8531761169433594e-05, 5.7756900787353516e-05, 5.729496479034424e-05]
I0108 21:45:01.276291 140441555372032 prune.py:304] reconstruction time 11.281371355056763
I0108 21:45:02.140504 140441555372032 prune.py:310] recon error 5.7110562920570374e-05
I0108 21:45:02.964072 140441555372032 prune.py:207] pruning layer 1
I0108 21:45:21.193104 140441555372032 finetune.py:129] weight params, number of params: 7087872, weight_decay: 0.0, lr: 0.0002
I0108 21:45:31.852060 140441555372032 finetune.py:123] [5.879346281290054e-05, 4.295259714126587e-05, 3.369152545928955e-05, 3.072991967201233e-05, 2.8897076845169067e-05, 2.771243453025818e-05, 2.6591122150421143e-05, 2.596527338027954e-05, 2.5492161512374878e-05, 2.5149434804916382e-05, 2.4944543838500977e-05]
I0108 21:45:31.852579 140441555372032 prune.py:304] reconstruction time 11.51256251335144
I0108 21:45:32.786397 140441555372032 prune.py:310] recon error 8.897297084331512e-05
I0108 21:45:33.597175 140441555372032 prune.py:207] pruning layer 2
I0108 21:45:51.653454 140441555372032 finetune.py:129] weight params, number of params: 7087872, weight_decay: 0.0, lr: 0.0002
I0108 21:46:02.063872 140441555372032 finetune.py:123] [6.416253745555878e-05, 4.491955041885376e-05, 3.5181641578674316e-05, 3.263354301452637e-05, 2.9921531677246094e-05, 2.8684735298156738e-05, 2.7980655431747437e-05, 2.728402614593506e-05, 2.6658177375793457e-05, 2.6348978281021118e-05, 2.6106834411621094e-05]
I0108 21:46:02.064383 140441555372032 prune.py:304] reconstruction time 11.253024101257324
I0108 21:46:02.886591 140441555372032 prune.py:310] recon error 0.00013227947056293488
I0108 21:46:03.659632 140441555372032 prune.py:207] pruning layer 3
I0108 21:46:24.322301 140441555372032 finetune.py:129] weight params, number of params: 7087872, weight_decay: 0.0, lr: 0.0002
I0108 21:46:34.820870 140441555372032 finetune.py:123] [7.053278386592865e-05, 3.6813318729400635e-05, 2.5723129510879517e-05, 2.3052096366882324e-05, 2.1871179342269897e-05, 2.032145857810974e-05, 1.9665807485580444e-05, 1.9252300262451172e-05, 1.8805265426635742e-05, 1.8652528524398804e-05, 1.827627420425415e-05]
I0108 21:46:34.821386 140441555372032 prune.py:304] reconstruction time 11.403014659881592
I0108 21:46:35.711265 140441555372032 prune.py:310] recon error 0.00016949139535427094
